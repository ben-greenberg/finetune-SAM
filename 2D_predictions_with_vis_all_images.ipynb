{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cnpt62A4RKrq","executionInfo":{"status":"ok","timestamp":1729157565335,"user_tz":-60,"elapsed":20598,"user":{"displayName":"Ben Greenberg","userId":"14416223526299671855"}},"outputId":"1cb43faa-cb38-4e73-9ab1-34ac402c079a"},"id":"Cnpt62A4RKrq","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip3 install monai torchio timm git+https://github.com/facebookresearch/segment-anything.git icecream slicerio"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8DzEv8JpR3qg","executionInfo":{"status":"ok","timestamp":1729157585563,"user_tz":-60,"elapsed":18285,"user":{"displayName":"Ben Greenberg","userId":"14416223526299671855"}},"outputId":"8bb13355-3c2b-4060-bcf1-8f885f3051f7"},"id":"8DzEv8JpR3qg","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/facebookresearch/segment-anything.git\n","  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-req-build-hd27y93g\n","  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /tmp/pip-req-build-hd27y93g\n","  Resolved https://github.com/facebookresearch/segment-anything.git to commit dca509fe793f601edb92606367a655c15ac00fdf\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting monai\n","  Downloading monai-1.4.0-py3-none-any.whl.metadata (11 kB)\n","Collecting torchio\n","  Downloading torchio-0.20.1-py3-none-any.whl.metadata (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting timm\n","  Downloading timm-1.0.11-py3-none-any.whl.metadata (48 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting icecream\n","  Downloading icecream-2.1.3-py2.py3-none-any.whl.metadata (1.4 kB)\n","Collecting slicerio\n","  Downloading slicerio-1.1.1-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy<2.0,>=1.24 in /usr/local/lib/python3.10/dist-packages (from monai) (1.26.4)\n","Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from monai) (2.4.1+cu121)\n","Requirement already satisfied: deprecated in /usr/local/lib/python3.10/dist-packages (from torchio) (1.2.14)\n","Requirement already satisfied: humanize in /usr/local/lib/python3.10/dist-packages (from torchio) (4.10.0)\n","Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (from torchio) (5.2.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torchio) (1.13.1)\n","Collecting simpleitk!=2.0.*,!=2.1.1.1 (from torchio)\n","  Downloading SimpleITK-2.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchio) (4.66.5)\n","Requirement already satisfied: typer in /usr/local/lib/python3.10/dist-packages (from torchio) (0.12.5)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.19.1+cu121)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.2)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.24.7)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.5)\n","Collecting colorama>=0.3.9 (from icecream)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: pygments>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from icecream) (2.18.0)\n","Collecting executing>=0.3.1 (from icecream)\n","  Downloading executing-2.1.0-py2.py3-none-any.whl.metadata (8.9 kB)\n","Collecting asttokens>=2.0.1 (from icecream)\n","  Downloading asttokens-2.4.1-py2.py3-none-any.whl.metadata (5.2 kB)\n","Collecting pynrrd (from slicerio)\n","  Downloading pynrrd-1.0.0-py2.py3-none-any.whl.metadata (3.9 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from slicerio) (2.32.3)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from asttokens>=2.0.1->icecream) (1.16.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (2024.6.1)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->torchio) (1.16.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.1)\n","Collecting nptyping (from pynrrd->slicerio)\n","  Downloading nptyping-2.5.0-py3-none-any.whl.metadata (7.6 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->slicerio) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->slicerio) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->slicerio) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->slicerio) (2024.8.30)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (10.4.0)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer->torchio) (8.1.7)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer->torchio) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer->torchio) (13.9.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer->torchio) (3.0.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->monai) (3.0.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9->monai) (1.3.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer->torchio) (0.1.2)\n","Downloading monai-1.4.0-py3-none-any.whl (1.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchio-0.20.1-py3-none-any.whl (175 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.5/175.5 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading timm-1.0.11-py3-none-any.whl (2.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading icecream-2.1.3-py2.py3-none-any.whl (8.4 kB)\n","Downloading slicerio-1.1.1-py3-none-any.whl (20 kB)\n","Downloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n","Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Downloading executing-2.1.0-py2.py3-none-any.whl (25 kB)\n","Downloading SimpleITK-2.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.4/52.4 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pynrrd-1.0.0-py2.py3-none-any.whl (19 kB)\n","Downloading nptyping-2.5.0-py3-none-any.whl (37 kB)\n","Building wheels for collected packages: segment_anything\n","  Building wheel for segment_anything (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for segment_anything: filename=segment_anything-1.0-py3-none-any.whl size=36590 sha256=a73d4da7729169c69e38c147a5eb93c7d23cbf07dca087f2c9a49ffb4c5a9fd0\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-by302mt0/wheels/10/cf/59/9ccb2f0a1bcc81d4fbd0e501680b5d088d690c6cfbc02dc99d\n","Successfully built segment_anything\n","Installing collected packages: simpleitk, segment_anything, nptyping, executing, colorama, asttokens, pynrrd, icecream, slicerio, monai, torchio, timm\n","Successfully installed asttokens-2.4.1 colorama-0.4.6 executing-2.1.0 icecream-2.1.3 monai-1.4.0 nptyping-2.5.0 pynrrd-1.0.0 segment_anything-1.0 simpleitk-2.4.0 slicerio-1.1.1 timm-1.0.11 torchio-0.20.1\n"]}]},{"cell_type":"code","execution_count":30,"id":"43d13ad5-f188-4b49-be18-e590ad332901","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"43d13ad5-f188-4b49-be18-e590ad332901","executionInfo":{"status":"ok","timestamp":1729166766516,"user_tz":-60,"elapsed":43797,"user":{"displayName":"Ben Greenberg","userId":"14416223526299671855"}},"outputId":"75093bfd-c24a-4f76-c0d4-da80e974261e"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 34/34 [00:40<00:00,  1.20s/it]"]},{"output_type":"stream","name":"stdout","text":["Combined Averages for All Images:\n","Class 0 - DSC: 0.9906, Accuracy: 0.9834, Precision: 0.9911, Recall: 0.9901, IoU: 0.9813\n","Class 1 - DSC: 0.8940, Accuracy: 0.9877, Precision: 0.8723, Recall: 0.9258, IoU: 0.8134\n","Class 2 - DSC: 0.7494, Accuracy: 0.9893, Precision: 0.7670, Recall: 0.7492, IoU: 0.6100\n","Class 3 - DSC: 0.6803, Accuracy: 0.9872, Precision: 0.7265, Recall: 0.6690, IoU: 0.5668\n","\n","Overall Averages Across All Classes for All Images:\n","DSC: 0.8286, Accuracy: 0.9869, Precision: 0.8392, Recall: 0.8335, IoU: 0.7429\n","All results saved to /content/drive/MyDrive/correct_dataset/split/finetune_testing_output_oct17\n","DSC results saved to /content/drive/MyDrive/correct_dataset/split/finetune_testing_output_oct17/dsc_results.csv\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["# appending a path\n","sys.path.append('/content/drive/MyDrive/finetuneSAMmain')\n","\n","import os\n","import torch\n","import json\n","from PIL import Image\n","import numpy as np\n","import csv\n","from torchvision import transforms\n","from utils.utils import inverse_normalize\n","from models.sam import sam_model_registry\n","from argparse import Namespace\n","from tqdm import tqdm\n","from pathlib import Path\n","import matplotlib.pyplot as plt\n","\n","# Directory paths\n","image_dir = '/content/drive/MyDrive/correct_dataset/split/test_images'\n","ground_truth_dir = '/content/drive/MyDrive/correct_dataset/split/test_masks'\n","output_dir = '/content/drive/MyDrive/correct_dataset/split/finetune_testing_output_oct17'\n","mask_output_dir = os.path.join(output_dir, 'masks')\n","dsc_output_file = os.path.join(output_dir, 'dsc_results.csv')\n","\n","# Create the output and mask output directories if they don't exist\n","Path(output_dir).mkdir(parents=True, exist_ok=True)\n","Path(mask_output_dir).mkdir(parents=True, exist_ok=True)\n","\n","# Load model\n","checkpoint_dir = \"/content/drive/MyDrive/correct_dataset/split/2D-SAM_vit_b_decoder_adapter_OCT-Ear_noprompt_Oct10\"\n","args_path = f\"{checkpoint_dir}/args.json\"\n","\n","with open(args_path, 'r') as f:\n","    args_dict = json.load(f)\n","\n","args = Namespace(**args_dict)\n","sam_fine_tune = sam_model_registry[args.arch](args, checkpoint=os.path.join(args.dir_checkpoint, 'checkpoint_best.pth'), num_classes=args.num_cls)\n","sam_fine_tune = sam_fine_tune.to('cuda').eval()\n","\n","def calculate_mean_std(image_folder):\n","    pixel_values = []\n","\n","    for image_filename in os.listdir(image_folder):\n","        image_path = os.path.join(image_folder, image_filename)\n","        if os.path.isfile(image_path) and image_filename.endswith(('.png', '.jpg', '.jpeg')):\n","            # Open the image and convert to grayscale\n","            image = Image.open(image_path).convert('L')\n","            image_array = np.array(image) / 255.0  # Normalize to range [0, 1]\n","            pixel_values.extend(image_array.flatten())\n","\n","    pixel_values = np.array(pixel_values)\n","    mean = np.mean(pixel_values)\n","    std = np.std(pixel_values)\n","\n","    return mean, std\n","\n","# Function to evaluate a single image slice\n","def evaluate_1_slice(image_path, model, mean, std):\n","    img = Image.open(image_path)\n","    Pil_img = img.copy()\n","\n","    img = transforms.Resize((1024, 1024))(img)\n","    transform_img = transforms.Compose([transforms.ToTensor()])\n","    img = transform_img(img)\n","    imgs = torch.unsqueeze(transforms.Normalize(mean=[mean], std=[std])(img), 0).cuda()\n","\n","    with torch.no_grad():\n","        img_emb = model.image_encoder(imgs)\n","        sparse_emb, dense_emb = model.prompt_encoder(points=None, boxes=None, masks=None)\n","        pred, _ = model.mask_decoder(\n","            image_embeddings=img_emb,\n","            image_pe=model.prompt_encoder.get_dense_pe(),\n","            sparse_prompt_embeddings=sparse_emb,\n","            dense_prompt_embeddings=dense_emb,\n","            multimask_output=True,\n","        )\n","        pred = pred.argmax(dim=1)\n","\n","    return pred, Pil_img\n","\n","# Define subdirectory paths for comparison images and colorized predictions\n","comparison_dir = os.path.join(output_dir, 'comparison')\n","colorized_predictions_dir = os.path.join(output_dir, 'colorized_predictions')\n","\n","# Create the subdirectories if they don't exist\n","Path(comparison_dir).mkdir(parents=True, exist_ok=True)\n","Path(colorized_predictions_dir).mkdir(parents=True, exist_ok=True)\n","\n","# Prepare CSV file to store DSC, accuracy, precision, recall, and IoU for each image\n","with open(dsc_output_file, mode='w', newline='') as dsc_file:\n","    # Header with metrics for each class (0 to num_classes - 1)\n","    dsc_writer = csv.writer(dsc_file)\n","    headers = ['Image Name']\n","    num_classes = 4  # Assuming 4 classes (0: background, 1-3: actual classes)\n","    for cls in range(num_classes):\n","        headers += [\n","            f'Class {cls} DSC', f'Class {cls} Accuracy', f'Class {cls} Precision',\n","            f'Class {cls} Recall', f'Class {cls} IoU'\n","        ]\n","    dsc_writer.writerow(headers)\n","\n","    # Initialize accumulators for combined averages\n","    total_metrics = {\n","        'dsc': np.zeros(num_classes),\n","        'accuracy': np.zeros(num_classes),\n","        'precision': np.zeros(num_classes),\n","        'recall': np.zeros(num_classes),\n","        'iou': np.zeros(num_classes)\n","    }\n","\n","    cumulative_sum_metrics = {\n","        'dsc': 0.0,\n","        'accuracy': 0.0,\n","        'precision': 0.0,\n","        'recall': 0.0,\n","        'iou': 0.0\n","    }\n","    image_count = 0  # To calculate the average later\n","\n","    mean, std = calculate_mean_std(image_dir)\n","\n","    # Iterate through all images in the directory\n","    for image_filename in tqdm(os.listdir(image_dir)):\n","        image_path = os.path.join(image_dir, image_filename)\n","        ground_truth_path = os.path.join(ground_truth_dir, image_filename.replace('.jpg', '.png'))\n","\n","        if os.path.exists(ground_truth_path):\n","            # Evaluate the image slice\n","            pred_1, ori_img = evaluate_1_slice(image_path, sam_fine_tune, mean, std)\n","\n","            # Convert predicted mask to a PIL image\n","            mask_pred_1 = ((pred_1).cpu()).float()\n","            pil_mask1 = Image.fromarray(np.array(mask_pred_1[0], dtype=np.uint8), 'L').resize(ori_img.size, resample=Image.NEAREST)\n","\n","            # Save predicted mask\n","            mask_img_filename = os.path.join(mask_output_dir, f'{os.path.splitext(image_filename)[0]}' + '.png')\n","            pil_mask1.save(mask_img_filename)\n","\n","            # Load ground truth mask and resize to match prediction size\n","            ground_truth_img = Image.open(ground_truth_path).convert('L').resize(ori_img.size, resample=Image.NEAREST)\n","            ground_truth_display = np.array(ground_truth_img)\n","\n","            # Initialize a list to store metrics for the current image\n","            image_metrics = [image_filename]\n","\n","            # Calculate DSC, accuracy, precision, recall, and IoU for each class\n","            mask_display = np.array(pil_mask1)\n","\n","            for cls in range(num_classes):\n","                pred_binary = (mask_display == cls).astype(float)\n","                gt_binary = (ground_truth_display == cls).astype(float)\n","\n","                # Calculate True Positives, False Positives, False Negatives, and True Negatives\n","                true_positive = np.sum(pred_binary * gt_binary)\n","                false_positive = np.sum(pred_binary * (1 - gt_binary))\n","                false_negative = np.sum((1 - pred_binary) * gt_binary)\n","                true_negative = np.sum((1 - pred_binary) * (1 - gt_binary))\n","\n","                # Calculate DSC (Dice Coefficient)\n","                union = 2 * true_positive + false_positive + false_negative\n","                dsc = (2 * true_positive / union) if union > 0 else 1.0\n","\n","                # Calculate Accuracy\n","                total_pixels = true_positive + false_positive + false_negative + true_negative\n","                accuracy = (true_positive + true_negative) / total_pixels if total_pixels > 0 else 1.0\n","\n","                # Calculate Precision\n","                precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 1.0\n","\n","                # Calculate Recall\n","                recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 1.0\n","\n","                # Calculate IoU (Jaccard Index)\n","                intersection = true_positive\n","                union = true_positive + false_positive + false_negative\n","                iou = intersection / union if union > 0 else 1.0\n","\n","                # Append the metrics for the current class to the row\n","                image_metrics += [dsc, accuracy, precision, recall, iou]\n","\n","                # Accumulate metrics for combined averages\n","                total_metrics['dsc'][cls] += dsc\n","                total_metrics['accuracy'][cls] += accuracy\n","                total_metrics['precision'][cls] += precision\n","                total_metrics['recall'][cls] += recall\n","                total_metrics['iou'][cls] += iou\n","\n","                # Accumulate the sum of metrics for overall averages\n","                cumulative_sum_metrics['dsc'] += dsc\n","                cumulative_sum_metrics['accuracy'] += accuracy\n","                cumulative_sum_metrics['precision'] += precision\n","                cumulative_sum_metrics['recall'] += recall\n","                cumulative_sum_metrics['iou'] += iou\n","\n","            # Write the metrics for this image (all classes) to the CSV\n","            dsc_writer.writerow(image_metrics)\n","            image_count += 1  # Increment image count for averaging\n","\n","            # Visualization and overlay code\n","            # Overlay colors: Red for class 1, Green for class 2, Blue for class 3\n","            overlay_colors = np.array([[0, 0, 1], [1, 0, 0], [0, 1, 0]])\n","\n","            # Create color overlays for the predicted mask\n","            pred_overlay = np.zeros((mask_display.shape[0], mask_display.shape[1], 3), dtype=np.float32)\n","            for cls in range(1, 4):  # Classes 1 to 3\n","                pred_overlay[mask_display == cls] = overlay_colors[cls - 1]\n","\n","            # Blend the original image with the predicted mask overlay\n","            alpha = 0.5\n","            ori_img_array = np.array(ori_img).astype(np.float32) / 255.0\n","            pred_blend = (1 - alpha) * ori_img_array + alpha * pred_overlay\n","\n","            # Save the RGB overlay of predicted masks in 'colorized_predictions' directory\n","            colorized_prediction_filename = os.path.join(colorized_predictions_dir, f'{os.path.splitext(image_filename)[0]}.png')\n","            plt.imsave(colorized_prediction_filename, pred_blend)\n","\n","            # Comparison visualization: original, predicted, and ground truth\n","            gt_overlay = np.zeros((ground_truth_display.shape[0], ground_truth_display.shape[1], 3), dtype=np.float32)\n","            for cls in range(1, 4):\n","                gt_overlay[ground_truth_display == cls] = overlay_colors[cls - 1]\n","\n","            gt_blend = (1 - alpha) * ori_img_array + alpha * gt_overlay\n","\n","            # Side-by-side comparison of original, predicted, and ground truth\n","            fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n","\n","            # Save the side-by-side comparison in the 'comparison' directory\n","            comparison_filename = os.path.join(comparison_dir, f'{os.path.splitext(image_filename)[0]}.png')\n","            axes[0].imshow(ori_img_array)\n","            axes[0].axis('off')\n","\n","            axes[1].imshow(pred_blend)\n","            axes[1].axis('off')\n","\n","            axes[2].imshow(gt_blend)\n","            axes[2].axis('off')\n","\n","            plt.tight_layout()\n","            plt.savefig(comparison_filename)\n","            plt.close()\n","\n","# Calculate and print average metrics for all images\n","if image_count > 0:\n","    avg_metrics = {key: total_metrics[key] / image_count for key in total_metrics}\n","    print(\"Combined Averages for All Images:\")\n","    for cls in range(num_classes):\n","        print(f\"Class {cls} - DSC: {avg_metrics['dsc'][cls]:.4f}, Accuracy: {avg_metrics['accuracy'][cls]:.4f}, Precision: {avg_metrics['precision'][cls]:.4f}, Recall: {avg_metrics['recall'][cls]:.4f}, IoU: {avg_metrics['iou'][cls]:.4f}\")\n","\n","    # Calculate and print overall averages across all classes\n","    overall_avg_metrics = {key: cumulative_sum_metrics[key] / (image_count * num_classes) for key in cumulative_sum_metrics}\n","    print(\"\\nOverall Averages Across All Classes for All Images:\")\n","    print(f\"DSC: {overall_avg_metrics['dsc']:.4f}, Accuracy: {overall_avg_metrics['accuracy']:.4f}, Precision: {overall_avg_metrics['precision']:.4f}, Recall: {overall_avg_metrics['recall']:.4f}, IoU: {overall_avg_metrics['iou']:.4f}\")\n","\n","print(f\"All results saved to {output_dir}\")\n","print(f\"DSC results saved to {dsc_output_file}\")\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"},"colab":{"provenance":[{"file_id":"1-ZrTGcqNw9826aOnzbbiQv6hAWS-FuLA","timestamp":1726502605572}],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}